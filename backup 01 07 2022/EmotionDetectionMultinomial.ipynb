{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import gensim\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_link_menzione(doc):\n",
    "    pattern_link=\"https\\S+\"\n",
    "    pattern_menzione=\"@\\S+\"\n",
    "    doc=re.sub(pattern_link, '',doc)\n",
    "    doc=re.sub(pattern_menzione,\" \",doc)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_merge_not(lista,all_stopwords):\n",
    "    tmp=''\n",
    "    parole_esaminate=[]\n",
    "    for parole in lista:\n",
    "        if parole == 'not':\n",
    "            tmp='not_'\n",
    "        elif tmp=='not_' and parole not in all_stopwords:\n",
    "            parole=tmp+parole\n",
    "            tmp=''\n",
    "        if parole != 'not' and parole not in all_stopwords:\n",
    "            parole_esaminate.append(parole)\n",
    "    return parole_esaminate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_corpus(tweets):                \n",
    "    tokens_ = [list(gensim.utils.tokenize(remove_link_menzione(tweet), lower=True)) for tweet in tweets]\n",
    "    \n",
    "    sp = spacy.load('en_core_web_sm')\n",
    "    all_stopwords = sp.Defaults.stop_words\n",
    "\n",
    "    wnl = WordNetLemmatizer()\n",
    "    lemmatized_string=[[wnl.lemmatize(words) for words in find_and_merge_not(lista,all_stopwords)] for lista in tokens_]\n",
    "    bigram_mdl = gensim.models.phrases.Phrases(lemmatized_string, min_count=1, threshold=2)##farglielo fare su tutto il corpus tokenizzato altrimenti non funziona se lo fai su una sola frase\n",
    "    \n",
    "    post=[bigram_mdl[l] for l in lemmatized_string]\n",
    "    \n",
    "    #lemmatized_bigram_string=[' '.join(word) for word in post]\n",
    "    return post,bigram_mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"text_emotion_esercizio.csv\")\n",
    "df=df[[\"sentiment\",\"content\"]]\n",
    "bigramLS_post,bigram_mdl=clear_corpus(df[\"content\"])\n",
    "df[\"content\"]=[Counter(tmp) for tmp in bigramLS_post]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = DictVectorizer(sparse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all=vectorizer.fit_transform(list(df[\"content\"]))\n",
    "y_all=list(df[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size = 0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train 0.61659375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.00      0.00      0.00        83\n",
      "     boredom       1.00      0.01      0.01       151\n",
      "       empty       0.98      0.06      0.11       672\n",
      "  enthusiasm       1.00      0.04      0.08       629\n",
      "         fun       0.98      0.20      0.33      1425\n",
      "   happiness       0.66      0.72      0.69      4148\n",
      "        hate       0.99      0.19      0.32      1093\n",
      "        love       0.77      0.61      0.68      3059\n",
      "     neutral       0.60      0.78      0.68      6861\n",
      "      relief       0.99      0.13      0.23      1224\n",
      "     sadness       0.76      0.59      0.66      4157\n",
      "    surprise       0.99      0.19      0.32      1758\n",
      "       worry       0.51      0.89      0.65      6740\n",
      "\n",
      "    accuracy                           0.62     32000\n",
      "   macro avg       0.79      0.34      0.37     32000\n",
      "weighted avg       0.71      0.62      0.58     32000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Train\",accuracy_score(y_train, mnb.predict(X_train)))\n",
    "print(classification_report(y_train, mnb.predict(X_train),zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Test 0.316375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.00      0.00      0.00        27\n",
      "     boredom       0.00      0.00      0.00        28\n",
      "       empty       0.00      0.00      0.00       155\n",
      "  enthusiasm       0.00      0.00      0.00       130\n",
      "         fun       0.00      0.00      0.00       351\n",
      "   happiness       0.31      0.31      0.31      1061\n",
      "        hate       0.27      0.01      0.02       230\n",
      "        love       0.45      0.30      0.36       783\n",
      "     neutral       0.33      0.44      0.38      1777\n",
      "      relief       0.00      0.00      0.00       302\n",
      "     sadness       0.28      0.18      0.22      1008\n",
      "    surprise       0.09      0.00      0.01       429\n",
      "       worry       0.30      0.58      0.40      1719\n",
      "\n",
      "    accuracy                           0.32      8000\n",
      "   macro avg       0.16      0.14      0.13      8000\n",
      "weighted avg       0.27      0.32      0.27      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Test\",accuracy_score(y_test, mnb.predict(X_test)))\n",
    "print(classification_report(y_test, mnb.predict(X_test),zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_adapter(tweet,vectorizer,bigram_mdl):\n",
    "    lista_token = gensim.utils.tokenize(remove_link_menzione(tweet), lower=True)\n",
    "    \n",
    "    sp = spacy.load('en_core_web_sm')\n",
    "    all_stopwords = sp.Defaults.stop_words\n",
    "\n",
    "    wnl = WordNetLemmatizer()\n",
    "    lemmatized_string=[wnl.lemmatize(words) for words in find_and_merge_not(lista_token,all_stopwords)]\n",
    "        \n",
    "    post=bigram_mdl[lemmatized_string]\n",
    "    return vectorizer.transform([Counter(post)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_prob(tweet,vectorizer,bigram_mdl,model):\n",
    "    tmp = model.predict_proba(tweet_adapter(tweet,vectorizer,bigram_mdl))\n",
    "    tmp2=list(tmp[0])\n",
    "    class2=list(model.classes_)\n",
    "    return sorted(dict(zip(class2,tmp2)).items(), key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=list_prob(\"I am so happy\",vectorizer,bigram_mdl,mnb)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c5217a3946e5a84d5ff067ec86c6c29aba46ea34fb35a222c2c09d02c172ab5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
