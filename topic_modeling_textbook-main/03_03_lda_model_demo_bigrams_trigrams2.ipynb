{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#1introduction\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "\n",
    "#Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "#spacy\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#vis\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import gensim\n",
    "from gensim.models import TfidfModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[\"i love my mum\",\"i love my mum\",\"i love my mum\",\"my dad in better shape\",\"i love my dad and my dad\",\"i love my mum and dad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(texts, allowed_postags=[\"NOUN\", \"ADJ\", \"VERB\", \"ADV\",\"PROPN\",\"PART\"]):\n",
    "    #nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    texts_out = []\n",
    "    for text in texts:\n",
    "        doc = nlp(text)\n",
    "        new_text = []\n",
    "        for token in doc:\n",
    "            if token.pos_ in allowed_postags:\n",
    "                new_text.append(token.lemma_)\n",
    "        final = \" \".join(new_text)\n",
    "        texts_out.append(final)\n",
    "    return (texts_out)\n",
    "\n",
    "def gen_words(texts):\n",
    "    final = []\n",
    "    for text in texts:\n",
    "        new = gensim.utils.simple_preprocess(text, deacc=True)\n",
    "        final.append(new)\n",
    "    return (final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import funzioni_preprocessing_text as fpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=json.load(open(\"allDocuments2.json\",\"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The fall of Roe v. Wade has pushed the U.S. into turbulence that feels all too familiar to those who lived through the pre-Roe era. We spoke to women who remember a time without Roe — and the early years after the 1973 ruling.\\nCatherine Starr told The New York Times in an interview that she had become pregnant when she was 16, and, without the option of a safe, legal abortion, she gave her baby up for adoption. She was 17 when she attended her first demonstration to push for abortion rights outside City Hall in St. Louis. It was May 24, 1973, just months after the Supreme Court ruled on Roe v. Wade. Starr went to the rally because she “wanted to be able to make sure that the next little girl that gets pregnant has an option,” she said.\\nThe same year that Roe was decided, our photographer William E. Sauro documented scenes inside Women's Medical Services (second and fourth photo), an abortion clinic on Walnut Street in downtown Philadelphia, and our photographer Librado Romero took pictures of workers inside the Women’s National Abortion Action Coalition office in New York (third photo).\\nIn 1981, our photographer John Sotomayor captured abortion rights activists dancing at a demonstration at Liberty and Church Streets in Manhattan to commemorate the eighth anniversary of the Supreme Court’s decision.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prova=\"i'm a new to not good samaritan don't you think covid-19 is a good thing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"NOUN\", \"ADJ\", \"VERB\", \"ADV\",\"PROPN\",\"PART\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRON I i\n",
      "AUX be 'm\n",
      "DET a a\n",
      "ADJ new new\n",
      "ADP to to\n",
      "PART not not\n",
      "ADJ good good\n",
      "PROPN samaritan samaritan\n",
      "AUX do do\n",
      "PART not n't\n",
      "PRON you you\n",
      "VERB think think\n",
      "PROPN covid-19 covid-19\n",
      "AUX be is\n",
      "DET a a\n",
      "ADJ good good\n",
      "NOUN thing thing\n"
     ]
    }
   ],
   "source": [
    "a=lemmatization([prova])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new not good samaritan not think covid-19 good thing']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['new', 'not', 'good', 'samaritan', 'not', 'think', 'covid', 'good', 'thing']]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_words(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['m', 'new', 'tw', 'not_good', 'samaritan', 'don', 't', 'think', 'covid', 'good', 'thing']]\n"
     ]
    }
   ],
   "source": [
    "print(fpt.clear_corpus([prova])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_texts = lemmatization(data)\n",
    "data_words = gen_words(lemmatized_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['love mum',\n",
       " 'love mum',\n",
       " 'love mum',\n",
       " 'dad well shape',\n",
       " 'love dad dad',\n",
       " 'love mum dad']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['love', 'mum'],\n",
       " ['love', 'mum'],\n",
       " ['love', 'mum'],\n",
       " ['dad', 'well', 'shape'],\n",
       " ['love', 'dad', 'dad'],\n",
       " ['love', 'mum', 'dad']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_phrases = gensim.models.Phrases(data_words, min_count=5, threshold=100)\n",
    "bigram = gensim.models.phrases.Phraser(bigram_phrases)\n",
    "data_bigrams = ([bigram[doc] for doc in data_words])\n",
    "\n",
    "trigram_phrases = gensim.models.Phrases(bigram_phrases[data_words], threshold=100)\n",
    "trigram = gensim.models.phrases.Phraser(trigram_phrases)\n",
    "data_bigrams_trigrams = ([trigram[bigram[doc]] for doc in data_bigrams])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['love', 'mum'],\n",
       " ['love', 'mum'],\n",
       " ['love', 'mum'],\n",
       " ['dad', 'well', 'shape'],\n",
       " ['love', 'dad', 'dad'],\n",
       " ['love', 'mum', 'dad']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['love', 'mum'],\n",
       " ['love', 'mum'],\n",
       " ['love', 'mum'],\n",
       " ['dad', 'well', 'shape'],\n",
       " ['love', 'dad', 'dad'],\n",
       " ['love', 'mum', 'dad']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bigrams_trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = gensim.corpora.Dictionary(data_bigrams_trigrams)\n",
    "\n",
    "texts = data_bigrams_trigrams\n",
    "\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "tfidf = TfidfModel(corpus, id2word=id2word)\n",
    "\n",
    "low_value = 0.03\n",
    "words  = []\n",
    "words_missing_in_tfidf = []\n",
    "for i in range(0, len(corpus)):\n",
    "    bow = corpus[i]\n",
    "    low_value_words = [] #reinitialize to be safe. You can skip this.\n",
    "    tfidf_ids = [id for id, value in tfidf[bow]]\n",
    "    bow_ids = [id for id, value in bow]\n",
    "    low_value_words = [id for id, value in tfidf[bow] if value < low_value]\n",
    "    drops = low_value_words+words_missing_in_tfidf\n",
    "    for item in drops:\n",
    "        words.append(id2word[item])\n",
    "    words_missing_in_tfidf = [id for id in bow_ids if id not in tfidf_ids] # The words with tf-idf socre 0 will be missing\n",
    "\n",
    "    new_bow = [b for b in bow if b[0] not in low_value_words and b[0] not in words_missing_in_tfidf]\n",
    "    corpus[i] = new_bow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word2 = gensim.corpora.Dictionary(data_bigrams_trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus2 = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf2 = TfidfModel(corpus2, id2word=id2word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.410107005098448), (1, 0.9120374139086519)]\n",
      "[(0, 0.410107005098448), (1, 0.9120374139086519)]\n",
      "[(0, 0.410107005098448), (1, 0.9120374139086519)]\n",
      "[(2, 0.26385258936279504), (3, 0.682049049221003), (4, 0.682049049221003)]\n",
      "[(0, 0.13039433685974838), (2, 0.9914622115415728)]\n",
      "[(0, 0.22140753228371998), (1, 0.49238845143712107), (2, 0.8417436174628159)]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(corpus2)):\n",
    "    print(tfidf2[corpus2[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1)]\n",
      "[(0, 1), (1, 1)]\n",
      "[(0, 1), (1, 1)]\n",
      "[(2, 1), (3, 1), (4, 1)]\n",
      "[(0, 1), (2, 2)]\n",
      "[(0, 1), (1, 1), (2, 1)]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(corpus2)):\n",
    "    print(corpus2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word3 = gensim.corpora.Dictionary(data_bigrams_trigrams)\n",
    "\n",
    "corpus3 = [id2word3.doc2bow(doc) for doc in data_bigrams_trigrams]\n",
    "tfidf3 = TfidfModel(corpus, id2word=id2word3)\n",
    "\n",
    "low_value = 0.2\n",
    "low_value_words = []\n",
    "for bow in corpus3:\n",
    "    low_value_words += [id for id, value in tfidf3[bow] if value < low_value]\n",
    "id2word3_2=copy.copy(id2word3)\n",
    "id2word3_2.filter_tokens(low_value_words)\n",
    "new_corpus3 = [id2word3_2.doc2bow(doc) for doc in data_bigrams_trigrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=10,\n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1)], [(0, 1), (1, 1)], [(0, 1), (1, 1)], [(2, 1), (3, 1), (4, 1)], [(0, 1), (2, 2)], [(0, 1), (1, 1), (2, 1)]]\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('love', 0.40297326),\n",
       " ('mum', 0.32395872),\n",
       " ('dad', 0.25726476),\n",
       " ('well', 0.0079016),\n",
       " ('shape', 0.007901599)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_doc = corpus[-1]\n",
    "result = lda_model.get_document_topics(test_doc)\n",
    "idxMax=max(result, key=lambda x: x[1])[0]\n",
    "lda_model.show_topic(idxMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.012870085),\n",
       " (1, 0.0128699625),\n",
       " (2, 0.026503067),\n",
       " (3, 0.012870058),\n",
       " (4, 0.012869979),\n",
       " (5, 0.012869807),\n",
       " (6, 0.012870204),\n",
       " (7, 0.012870204),\n",
       " (8, 0.8705361),\n",
       " (9, 0.012870537)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.045874324), (1, 0.035836946), (2, 0.4376528), (5, 0.15934138), (7, 0.057556253), (8, 0.07231899), (9, 0.19118835)]\n",
      "[(2, 0.4376528), (9, 0.19118835), (5, 0.15934138), (8, 0.07231899), (7, 0.057556253), (0, 0.045874324), (1, 0.035836946)]\n"
     ]
    }
   ],
   "source": [
    "test_doc = corpus[-1]\n",
    "\n",
    "vector = lda_model[test_doc]\n",
    "print (vector)\n",
    "\n",
    "def Sort(sub_li):\n",
    "    sub_li.sort(key = lambda x: x[1])\n",
    "    sub_li.reverse()\n",
    "    return (sub_li)\n",
    "new_vector = Sort(vector)\n",
    "print (new_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.save(\"models/test_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = gensim.models.ldamodel.LdaModel.load(\"models/test_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.045875695), (1, 0.035836957), (2, 0.43765357), (5, 0.15934144), (7, 0.057556026), (8, 0.072318755), (9, 0.1911866)]\n",
      "[(2, 0.43765357), (9, 0.1911866), (5, 0.15934144), (8, 0.072318755), (7, 0.057556026), (0, 0.045875695), (1, 0.035836957)]\n"
     ]
    }
   ],
   "source": [
    "test_doc = corpus[-1]\n",
    "\n",
    "vector = new_model[test_doc]\n",
    "print (vector)\n",
    "\n",
    "def Sort(sub_li):\n",
    "    sub_li.sort(key = lambda x: x[1])\n",
    "    sub_li.reverse()\n",
    "    return (sub_li)\n",
    "new_vector = Sort(vector)\n",
    "print (new_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vizualizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word, mds=\"mmds\", R=30)\n",
    "# vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c5217a3946e5a84d5ff067ec86c6c29aba46ea34fb35a222c2c09d02c172ab5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
